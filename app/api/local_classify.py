"""
æœ¬åœ°æ¨¡å‹åˆ†ç±»æ¥å£è·¯ç”±
/api/v1/local-classify - ä½¿ç”¨æœ¬åœ°ONNXæ¨¡å‹è¿›è¡Œå›¾ç‰‡åˆ†ç±»
"""

from fastapi import APIRouter, File, UploadFile, HTTPException, Request, Header
from typing import Optional
from datetime import datetime
import time

from app.models.schemas import ClassificationResponse, ClassificationData, ErrorResponse
from app.services.local_model_inference import local_model_inference
from app.services.stats_service import stats_service
from app.utils.image_utils import ImageUtils
from app.utils.hash_utils import HashUtils
from app.utils.id_generator import IDGenerator
from loguru import logger

router = APIRouter(prefix="/api/v1", tags=["local-classify"])


@router.post("/local-classify")
async def classify_image_local(
    image: UploadFile = File(..., description="å›¾ç‰‡æ–‡ä»¶"),
    request: Request = None
):
    """
    æœ¬åœ°æ¨¡å‹å›¾ç‰‡åˆ†ç±»æ¥å£ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    ä½¿ç”¨æœ¬åœ°ONNXæ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè¿”å›åŸå§‹æ£€æµ‹ç»“æœ
    æ”¯æŒä¸‰ä¸ªæ¨¡å‹ï¼šIDå¡è¯†åˆ«ã€YOLO8sé€šç”¨æ£€æµ‹ã€MobileNetV3å›¾åƒåˆ†ç±»
    
    æ³¨æ„ï¼š
    - åªè¿”å›åŸå§‹æ£€æµ‹ç»“æœï¼Œä¸åŒ…å«categoryIdï¼ˆç”±å®¢æˆ·ç«¯æ˜ å°„ï¼‰
    - æ¨èä½¿ç”¨ /local-classify/detailed æ¥å£è·å–å®Œæ•´ä¿¡æ¯
    """
    try:
        # è¯»å–å›¾ç‰‡æ•°æ®
        image_bytes = await image.read()
        
        # éªŒè¯å›¾ç‰‡
        is_valid, error_msg = ImageUtils.validate_image(image_bytes)
        if not is_valid:
            raise HTTPException(status_code=400, detail=error_msg)
        
        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        if not local_model_inference.is_initialized:
            logger.info("ğŸš€ é¦–æ¬¡è°ƒç”¨ï¼Œåˆå§‹åŒ–æœ¬åœ°æ¨¡å‹...")
            await local_model_inference.initialize()
        
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œæ¨ç†
        result = await local_model_inference.classify_image(image_bytes)
        
        if not result['success']:
            raise HTTPException(status_code=500, detail=result['message'])
        
        # è¿”å›ç®€åŒ–ç»“æœ
        return {
            "success": True,
            "message": result['message'],
            "idCardDetections": result['idCardDetections'],
            "generalDetections": result['generalDetections'],
            "mobileNetV3Detections": result['mobileNetV3Detections'],
            "timestamp": datetime.now()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æœ¬åœ°æ¨¡å‹åˆ†ç±»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/local-classify/detailed", summary="æœ¬åœ°æ¨¡å‹åˆ†ç±»ï¼ˆè¯¦ç»†ç»“æœï¼‰")
async def classify_image_local_detailed(
    image: UploadFile = File(..., description="å›¾ç‰‡æ–‡ä»¶"),
    x_user_id: Optional[str] = Header(None, alias="X-User-ID"),
    request: Request = None
):
    """
    æœ¬åœ°æ¨¡å‹å›¾ç‰‡åˆ†ç±»æ¥å£ï¼ˆè¿”å›è¯¦ç»†æ£€æµ‹ç»“æœï¼‰
    
    è¿”å›æ‰€æœ‰æ¨¡å‹çš„æ£€æµ‹ç»“æœï¼ŒåŒ…æ‹¬ï¼š
    - IDå¡æ£€æµ‹ç»“æœ
    - YOLO8sé€šç”¨æ£€æµ‹ç»“æœ
    - MobileNetV3åˆ†ç±»ç»“æœ
    
    æ³¨æ„ï¼š
    - ä¸è¿”å› categoryIdï¼ˆç”±å®¢æˆ·ç«¯æ ¹æ®æ£€æµ‹ç»“æœæ˜ å°„ï¼‰
    - ä¸è¿”å› imageDimensionsï¼ˆå®¢æˆ·ç«¯æä¾›åŸå§‹å°ºå¯¸ï¼‰
    - ä¼šè®°å½•ç»Ÿè®¡æ•°æ®ï¼ˆæ¨ç†æ–¹å¼ä¸º 'local_test'ï¼‰
    """
    try:
        # è¯»å–å›¾ç‰‡æ•°æ®
        image_bytes = await image.read()
        
        # éªŒè¯å›¾ç‰‡
        is_valid, error_msg = ImageUtils.validate_image(image_bytes)
        if not is_valid:
            raise HTTPException(status_code=400, detail=error_msg)
        
        # ç”Ÿæˆè¯·æ±‚IDå’Œè®¡ç®—å“ˆå¸Œ
        request_id = IDGenerator.generate_request_id()
        image_hash = HashUtils.calculate_sha256(image_bytes)
        image_size = len(image_bytes)
        user_id = x_user_id or "admin_test"
        ip_address = request.client.host if request else None
        
        start_time = time.time()
        
        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        if not local_model_inference.is_initialized:
            logger.info("ğŸš€ é¦–æ¬¡è°ƒç”¨ï¼Œåˆå§‹åŒ–æœ¬åœ°æ¨¡å‹...")
            await local_model_inference.initialize()
        
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œæ¨ç†
        result = await local_model_inference.classify_image(image_bytes)
        
        processing_time = int((time.time() - start_time) * 1000)
        
        if not result['success']:
            raise HTTPException(status_code=500, detail=result['message'])
        
        # è®°å½•ç»Ÿè®¡æ•°æ®
        await stats_service.log_request(
            request_id=request_id,
            user_id=user_id,
            ip_address=ip_address,
            image_hash=image_hash,
            image_size=image_size,
            category="local_test",  # æ ‡è®°ä¸ºæµ‹è¯•
            confidence=0.8,
            from_cache=False,
            processing_time_ms=processing_time,
            inference_method="local_test"  # ç®¡ç†åå°æµ‹è¯•
        )
        
        logger.info(f"æœ¬åœ°æ¨¡å‹æµ‹è¯•å®Œæˆ [{request_id}]: {processing_time}ms")
        
        # è¿”å›åŸå§‹æ£€æµ‹ç»“æœ
        return {
            "success": True,
            "message": result['message'],
            "details": {
                "idCardDetections": result['idCardDetections'],
                "generalDetections": result['generalDetections'],
                "mobileNetV3Detections": result['mobileNetV3Detections']
            },
            "processing_time_ms": processing_time,
            "request_id": request_id,
            "timestamp": datetime.now()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æœ¬åœ°æ¨¡å‹åˆ†ç±»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/local-classify/models", summary="è·å–æœ¬åœ°æ¨¡å‹çŠ¶æ€")
async def get_local_models_status():
    """
    è·å–æœ¬åœ°æ¨¡å‹åŠ è½½çŠ¶æ€
    """
    try:
        return {
            "initialized": local_model_inference.is_initialized,
            "models": {
                name: {
                    "loaded": name in local_model_inference.models,
                    "path": path
                }
                for name, path in local_model_inference.model_paths.items()
            },
            "total_models": len(local_model_inference.model_paths),
            "loaded_models": len(local_model_inference.models)
        }
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

