# 推理统计功能说明 📊

## 🎉 完成内容

已成功实现大模型失败和本地推理调用次数的统计功能！

## ✅ 新增功能

### 1. 数据库字段
- ✅ `request_log.inference_method` - 推理方式字段
  - `cache` - 缓存命中
  - `llm` - 大模型成功
  - `local` - 本地推理（开关开启）
  - `llm_fallback` - 本地失败后大模型成功
  - `local_fallback` - 大模型失败后本地推理成功

### 2. 统计API
- ✅ `GET /api/v1/stats/inference-method` - 获取推理方式统计

### 3. 管理后台显示
- ✅ 新增"🤖 推理方式统计"卡片
- ✅ 实时显示各种推理方式的调用次数
- ✅ 自动计算百分比和失败率

### 4. 运行时配置
- ✅ 在Web界面直接开关本地推理
- ✅ 立即生效，无需重启服务
- ✅ 自动调用API更新配置

## 📊 统计指标

### 第一行统计卡片

| 指标 | 说明 |
|------|------|
| **今日总请求** | 所有分类请求总数 |
| **缓存命中** | 从缓存返回的请求数 |
| **大模型调用成功** | 直接调用大模型成功的次数 |
| **本地推理总次数** | 所有使用本地推理的次数（直接+降级） |

### 第二行详细统计

| 指标 | 说明 | 颜色 |
|------|------|------|
| **大模型调用失败** | 大模型失败后降级到本地推理的次数 | 红色 |
| **本地推理降级成功** | 大模型失败后本地推理成功次数 | 绿色 |
| **本地推理直接调用** | 开关开启时直接调用本地推理的次数 | 蓝色 |
| **大模型失败率** | 大模型失败次数 / 总请求数 | 黄色 |

## 🚀 使用方法

### 1. 查看统计
```
访问: http://123.57.68.4:8000
登录: zywl / zywl@123
点击: 📊 统计数据
滚动到: 🤖 推理方式统计
```

### 2. 开启本地推理
```
点击: ⚙️ 配置管理
找到: 🤖 推理策略配置
勾选: ☑️ 使用本地推理
自动: ✅ 配置已更新并立即生效
```

### 3. 测试效果
```
点击: 🧪 分类测试
上传图片: 选择测试图片
查看: 使用本地推理（速度更快）
返回统计页: 看到"本地推理直接调用"增加
```

## 📈 数据示例

```
🤖 推理方式统计

第一行:
┌─────────────┬─────────────┬─────────────┬─────────────┐
│  今日总请求  │   缓存命中   │大模型调用成功│本地推理总次数│
│     156     │      98     │      45     │      13     │
│             │   62.8%     │             │直接:3|降级:10│
└─────────────┴─────────────┴─────────────┴─────────────┘

第二行:
┌─────────────┬─────────────┬─────────────┬─────────────┐
│大模型调用失败│本地推理降级成│本地推理直接调│ 大模型失败率 │
│     10      │      10     │      3      │    6.4%     │
│已降级到本地推│保障服务可用性│  开关开启   │             │
└─────────────┴─────────────┴─────────────┴─────────────┘
```

## 🔧 配置方式对比

### 运行时配置（Web界面）✅ 推荐

**优点**:
- ✅ 立即生效，无需重启
- ✅ 可视化操作
- ✅ 实时反馈

**操作**:
1. 管理后台 → 配置管理
2. 勾选开关
3. 自动更新并生效

**注意**: 重启服务后会恢复.env中的配置

### 持久化配置（.env文件）

**优点**:
- ✅ 永久生效
- ✅ 重启后保持

**操作**:
```bash
# 编辑.env文件
echo "USE_LOCAL_INFERENCE=true" >> /opt/ImageClassifierBackend/.env
echo "LOCAL_INFERENCE_FALLBACK=true" >> /opt/ImageClassifierBackend/.env

# 重启服务
systemctl restart image-classifier
```

## 📝 API接口

### 获取推理配置
```http
GET /api/v1/config/inference
Authorization: Bearer {token}

Response:
{
  "use_local_inference": false,
  "local_inference_fallback": true
}
```

### 更新推理配置
```http
PUT /api/v1/config/inference
Authorization: Bearer {token}
Content-Type: application/json

{
  "use_local_inference": true,
  "local_inference_fallback": true
}

Response:
{
  "use_local_inference": true,
  "local_inference_fallback": true
}
```

### 获取推理方式统计
```http
GET /api/v1/stats/inference-method
Authorization: Bearer {token}

Response:
{
  "success": true,
  "data": {
    "total_requests": 156,
    "from_cache": 98,
    "llm_success": 45,
    "local_direct": 3,
    "local_fallback_success": 10,
    "llm_fail_count": 10,
    "local_total": 13
  }
}
```

## ✅ 部署清单

- [x] 数据库添加inference_method字段
- [x] 更新stats_service.py（添加推理方式统计）
- [x] 更新classifier.py（记录推理方式）
- [x] 新增config.py API（运行时配置）
- [x] 更新stats.py（添加统计端点）
- [x] 更新Web界面（添加统计显示）
- [x] 更新Web界面（添加配置开关）
- [x] 上传并重启服务

## 🚀 立即测试

```
1. 访问: http://123.57.68.4:8000
2. 登录: zywl / zywl@123
3. 查看统计: 📊 统计数据 → 🤖 推理方式统计
4. 开启开关: ⚙️ 配置管理 → 勾选"使用本地推理"
5. 测试推理: 🧪 分类测试 → 上传图片
6. 返回统计: 查看"本地推理直接调用"数量增加
```

**所有功能已部署完成！** 🎉

---

**完成日期**: 2025-10-11  
**新增统计**: 推理方式统计（大模型失败/本地推理调用）  
**配置方式**: Web界面运行时配置 + .env文件持久化

