# 本地模型推理使用说明

## 📋 概述

本地模型推理服务使用ONNX Runtime对上传的图片进行推理，支持三个神经网络模型：

1. **ID卡识别模型** (`id_card_detection.onnx`) - 检测身份证正反面
2. **YOLO8s通用检测模型** (`yolov8s.onnx`) - 检测80种常见物体（COCO数据集）
3. **MobileNetV3图像分类模型** (`mobilenetv3_rw_Opset17.onnx`) - ImageNet 1000类图像分类

## 🗂️ 文件结构

```
ImageClassifierBackend/
├── app/
│   ├── models/
│   │   ├── id_card_detection.onnx      # ID卡检测模型
│   │   ├── yolov8s.onnx                # YOLO8s通用检测模型
│   │   └── mobilenetv3_rw_Opset17.onnx # MobileNetV3分类模型
│   └── services/
│       └── local_model_inference.py    # 本地模型推理服务
├── test_local_inference.py             # 测试脚本
└── 本地模型推理使用说明.md              # 本文档
```

## 📦 依赖安装

确保已安装以下依赖：

```bash
pip install onnxruntime==1.16.3
pip install numpy==1.24.3
pip install Pillow==10.2.0
```

或者直接安装所有依赖：

```bash
pip install -r requirements.txt
```

## 🚀 使用方法

### 1. 基本使用

```python
import asyncio
from app.services.local_model_inference import local_model_inference

async def main():
    # 初始化模型
    await local_model_inference.initialize()
    
    # 读取图片
    with open("test_image.jpg", "rb") as f:
        image_bytes = f.read()
    
    # 执行推理
    result = await local_model_inference.classify_image(image_bytes)
    
    # 查看结果
    print(f"分类: {result['categoryId']}")
    print(f"置信度: {result['confidence']}")
    print(f"消息: {result['message']}")

asyncio.run(main())
```

### 2. 输出格式

推理结果与客户端代码保持一致，包含以下字段：

```python
{
    'success': bool,           # 是否成功
    'categoryId': str,         # 分类ID (见下方分类列表)
    'confidence': float,       # 置信度 (0-1)
    'message': str,            # 消息描述
    
    # 检测结果详情
    'idCardDetections': [      # ID卡检测结果
        {
            'classId': int,
            'className': str,
            'confidence': float,
            'bbox': [x, y, w, h]
        }
    ],
    'generalDetections': [     # 通用物体检测结果
        {
            'classId': int,
            'className': str,
            'confidence': float,
            'bbox': [x, y, w, h]
        }
    ],
    'mobileNetV3Detections': { # MobileNetV3分类结果
        'predictions': [
            {
                'index': int,
                'probability': float,
                'class': str
            }
        ],
        'topPrediction': {...},
        'confidence': float
    },
    
    # 图片信息
    'imageDimensions': {
        'width': int,
        'height': int
    },
    
    # 所有模型原始结果
    'allModelResults': {
        'mobileScreenshot': bool,
        'idCard': [...],
        'general': [...],
        'mobileNetV3': {...}
    }
}
```

## 🏷️ 支持的分类类别

| 分类ID | 中文名称 | 说明 |
|--------|---------|------|
| `social_activities` | 社交活动 | 多人合照、聚会等 |
| `pets` | 宠物萌照 | 猫、狗、鸟等宠物 |
| `single_person` | 单人照片 | 单人肖像、自拍等 |
| `foods` | 美食记录 | 食物、餐饮照片 |
| `travel_scenery` | 旅行风景 | 风景、建筑、旅游照片 |
| `screenshot` | 手机截图 | 手机屏幕截图 |
| `idcard` | 证件照 | 身份证、证件类照片 |
| `other` | 其它 | 无法明确分类的照片 |

## 🔧 分类逻辑

分类按以下优先级进行：

1. **身份证检测** - 检测到身份证正反面 → `idcard`
2. **人物检测**
   - 单人 → `single_person`
   - 多人 → `social_activities`
3. **宠物检测** - 检测到猫、狗、鸟等 → `pets`
4. **美食检测** - 检测到食物相关物体 → `foods`
5. **风景检测** - 检测物体较少或无明显主体 → `travel_scenery`
6. **默认分类** - 无法明确分类时返回 `other`

**注意**：手机截图识别应在客户端完成（上传前判断），因为服务器收到的图片已经过缩放处理。

## 🧪 测试

运行测试脚本：

```bash
python test_local_inference.py
```

测试脚本会：
1. 初始化所有模型
2. 验证输出格式兼容性
3. 对测试图片进行推理（如果提供）

## ⚙️ 模型配置

可以在 `local_model_inference.py` 中调整模型参数：

```python
self.model_configs = {
    "idCard": {
        "confidence_threshold": 0.7,  # 置信度阈值
        "nms_threshold": 0.4,         # NMS阈值
        "input_size": 640             # 输入尺寸
    },
    "yolo8s": {
        "confidence_threshold": 0.25,
        "nms_threshold": 0.4,
        "input_size": 640
    },
    "mobilenetv3": {
        "confidence_threshold": 0.3,
        "input_size": 224
    }
}
```

## 🚀 性能优化

### GPU加速

如果有NVIDIA GPU，可以安装CUDA版本的ONNX Runtime以获得更好的性能：

```bash
pip uninstall onnxruntime
pip install onnxruntime-gpu==1.16.3
```

### 批量推理

对于批量图片处理，可以考虑：
1. 复用已加载的模型（避免重复初始化）
2. 使用异步并发处理多张图片
3. 合理设置置信度阈值以平衡速度和准确性

## 📊 YOLO8s检测的物体类别

YOLO8s支持80种COCO数据集类别，包括：

- **人物**: person
- **动物**: bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe
- **交通工具**: bicycle, car, motorcycle, airplane, bus, train, truck, boat
- **家具**: chair, couch, bed, dining table, toilet
- **电子产品**: tv, laptop, mouse, keyboard, cell phone
- **食物**: banana, apple, sandwich, orange, pizza, donut, cake
- 等共80个类别

详细类别列表请参考代码中的 `_load_coco_classes()` 方法。

## 🐛 故障排查

### 模型加载失败

**问题**: `模型文件不存在: xxx.onnx`

**解决**: 
- 确保三个ONNX模型文件都在 `app/models/` 目录下
- 检查文件名是否正确

### 内存不足

**问题**: 推理时内存溢出

**解决**:
- 降低图片分辨率（推理前会自动缩放）
- 只加载需要的模型
- 使用GPU加速

### 推理速度慢

**问题**: 推理耗时过长

**解决**:
- 安装GPU版本的ONNX Runtime
- 降低confidence_threshold以减少检测结果
- 考虑使用更小的模型

## 📝 集成到FastAPI

如果需要将本地推理集成到现有的FastAPI服务中：

```python
from app.services.local_model_inference import local_model_inference
from app.services.model_client import model_client

async def classify_image_hybrid(image_bytes: bytes, use_local: bool = False):
    """混合分类策略"""
    if use_local:
        # 使用本地模型推理
        return await local_model_inference.classify_image(image_bytes)
    else:
        # 使用大模型API
        return await model_client.classify_image(image_bytes)
```

## 🔗 相关文档

- [ONNX Runtime 官方文档](https://onnxruntime.ai/)
- [YOLO8 官方文档](https://docs.ultralytics.com/)
- [MobileNetV3 论文](https://arxiv.org/abs/1905.02244)

## 📞 技术支持

如有问题，请查看：
- 日志输出（使用loguru记录详细日志）
- 测试脚本输出
- 模型配置参数

---

**版本**: 1.0.0  
**更新日期**: 2025-10-11  
**作者**: ImageClassifier Backend Team

